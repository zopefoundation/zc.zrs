ZRS Secondary Storages with Blobs
=================================

ZRS Secondary storages are "read-only" storages that get their data by
downloading data from ZRS primary storages.  They manage downlaoded
data by "wrapping" other storages.

In this demonstration, we'll use a file storage with blobs enabled to
hold our secondary data:

    >>> import ZODB.FileStorage, ZODB.blob
    >>> fs = ZODB.FileStorage.FileStorage('Data.fs', blob_dir='blobs')

To create a secondary storage, we supply:

- The underlying storage

- The address to connect to, and

- An optional Twisted reactor to register with.  Normally, ZRS manages
  it's own reactor, but for demonstration/test purposes, we can pass
  in a special reactor that lets us demonstrate primary
  storages without actually creating network connections.

Let's create a secondary storage:

    >>> import zc.zrs.secondary
    >>> ss = zc.zrs.secondary.Secondary(fs, ('', 8000), reactor)
    INFO zc.zrs.secondary:
    Opening Data.fs ('', 8000)
    INFO zc.zrs.reactor:
    Starting factory <zc.zrs.secondary.SecondaryFactory>

We can't use a secondary storage until it has gotten some data.  Our
demo reactor doesn't make any network connections, so of course, the
storage doesn't have any data yet.  The demo reactor simulates
connections by creatiing client connections when we call accept.
Let's accept the connection, getting the client connection created for
this server:

    >>> connection = reactor.accept()
    INFO zc.zrs.secondary:
    IPv4Address(TCP, '127.0.0.1', 47245): Connected

The secondary server writes two messages to the connection to begin
the interaction with the server.  The first is the ZRS protocol
identifier:

    >>> connection.read()
    b'zrs2.1'

Because a blob storage is used, the 2.1 proocol is presented.

The second message is the identifier of the last transaction seen by
the client.  This client doesn't have any data, so we'll get a
transaction id consisting of all zeros:

    >>> connection.read()
    b'\x00\x00\x00\x00\x00\x00\x00\x00'

This is all the data sent by the client.  From this point on, the
client passively waits for data sent by the server.  We'll pass it
some data.  To do this, we'll get some help from a file-storage
iterator that will give us the data we need to send.  We'll create a
file storage and database that we can use for this:

    >>> primary_fs = ZODB.FileStorage.FileStorage(
    ...     'primary.fs', blob_dir='primary_blobs')
    >>> import zc.zrs.primary
    >>> primary_data = zc.zrs.primary.FileStorageIterator(primary_fs)

    >>> from ZODB.DB import DB
    >>> primary_db = DB(primary_fs)

The first transaction initializes the database.  Let's send that to
the secondary.

    >>> trans = primary_data.next()

Transactions are sent as a series of messages.  To make this easier
for this demonstration, the test connections let us pass data directly.

The first message is a transaction message that starts the transaction
and includes transaction meta data.

    >>> connection.send(('T', (trans.tid, trans.status, trans.user,
    ...                        trans.description, trans._extension)))

This initial message is followed by a serious of messages, two for
each object store. The first has record meta data as a pickle, and the
second has the record data:

    >>> for record in trans:
    ...     connection.send(('S', (record.oid, record.tid, record.version,
    ...                            record.data_txn)))
    ...     connection.send(record.data, raw=True)

Finally, a commit message is sent marking the end of the transaction:

    >>> connection.send(('C', (connection.md5.digest(),)))

Now that we've created this minimal data, we can create a database for
our secondary storage:

    >>> db = DB(ss)
    >>> conn = db.open()
    >>> root = conn.root()
    >>> root
    {}

Let's send some more data.

    >>> primary_conn = primary_db.open()
    >>> proot = primary_conn.root()
    >>> import persistent.mapping
    >>> proot['x'] = persistent.mapping.PersistentMapping()
    >>> commit()

    >>> blob_block_size = 1 << 16
    >>> def send_transaction():
    ...     trans = primary_data.next()
    ...     connection.send(('T', (trans.tid, trans.status, trans.user,
    ...                            trans.description, trans._extension)))
    ...     for record in trans:
    ...         if zc.zrs.primary.is_blob_record(record.data):
    ...             try:
    ...                 fname = primary_fs.loadBlob(
    ...                     record.oid, record.tid)
    ...                 f = open(fname, 'rb')
    ...             except (IOError, ZODB.POSException.POSKeyError):
    ...                 pass
    ...             else:
    ...                 f.seek(0, 2)
    ...                 blob_size = f.tell()
    ...                 blocks, r = divmod(blob_size, blob_block_size)
    ...                 if r:
    ...                     blocks += 1
    ...                 connection.send(('B',
    ...                                 (record.oid, record.tid, record.version,
    ...                                  record.data_txn, blocks)))
    ...                 connection.send(record.data, raw=True)
    ...                 f.seek(0)
    ...                 while blocks > 0:
    ...                     data = f.read(blob_block_size)
    ...                     if not data:
    ...                         raise AssertionError("Too much blob data")
    ...                     blocks -= 1
    ...                     connection.send(data, raw=True)
    ...                 f.close()
    ...                 continue
    ...         connection.send(('S', (record.oid, record.tid,
    ...                                record.version,
    ...                               record.data_txn)))
    ...         connection.send(record.data, raw=True)
    ...     connection.send(('C', (connection.md5.digest(),)))

    >>> send_transaction()

We'll see the data in the secondary database, and on the secondary
connection, after a sync:

    >>> conn.sync()
    >>> root
    {'x': {}}

Now, let's create some blob data:

    >>> proot['blob'] = ZODB.blob.Blob()
    >>> _ = proot['blob'].open('w').write(b'test\n')
    >>> commit()
    >>> send_transaction()

    >>> conn.sync(); root['blob'].open().read()
    b'test\n'

Let's create some more interesting blob data.

    >>> import random, struct
    >>> random.seed(0)
    >>> for i in range(5):
    ...     wdata = b''.join(struct.pack(">I", random.randint(0, 1<<32))
    ...                     for i in range(random.randint(1000, 100000)))
    ...     proot[i] = ZODB.blob.Blob()
    ...     _ = proot[i].open('w').write(wdata)
    ...     commit()
    ...     send_transaction()
    ...     conn.sync()
    ...     print_(root[i].open().read() == proot[i].open().read())
    True
    True
    True
    True
    True

    >>> proot['empty'] = ZODB.blob.Blob()
    >>> commit()
    >>> send_transaction()

    >>> conn.sync()
    >>> root['empty'].__class__
    <class 'ZODB.blob.Blob'>

    >>> root['empty'].open().read() # doctest: +ELLIPSIS
    Traceback (most recent call last):
    ...
    POSKeyError: u'No blob file at ...

    >>> _ = proot['empty'].open('w').write(b'new data')
    >>> commit()
    >>> send_transaction()
    >>> conn.sync()
    >>> root['empty'].open().read()
    b'new data'


.. cleanup

    >>> primary_db.close()
    >>> db.close() # doctest: +NORMALIZE_WHITESPACE
    INFO zc.zrs.secondary:
    Closing Data.fs ('', 8000)
    INFO zc.zrs.secondary:
    IPv4Address(TCP, '127.0.0.1', 47245): Disconnected
    <twisted.python.failure.Failure
     twisted.internet.error.ConnectionDone: Connection was closed cleanly.>

    >>> reactor.doLater()
    >>> reactor.later
    []

    Because we closed the secondary, the connector doesn't try to connect:

    >>> reactor.clients
    []
